{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Sentiment analysis with twitter data for Apple",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DotBion/fluffy-fishstick/blob/dev-nc3610/Sentiment_analysis_with_twitter_data_for_Apple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "omermetinn_tweets_about_the_top_companies_from_2015_to_2020_path = kagglehub.dataset_download('omermetinn/tweets-about-the-top-companies-from-2015-to-2020')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "gUwQykr9lTfk",
        "outputId": "fd14ef3a-5cfb-4b6f-882f-80f048610f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/omermetinn/tweets-about-the-top-companies-from-2015-to-2020?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278M/278M [00:04<00:00, 59.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read the folder to see csv files\n",
        "\n",
        "import os\n",
        "print(os.listdir(omermetinn_tweets_about_the_top_companies_from_2015_to_2020_path))\n"
      ],
      "metadata": {
        "id": "mzkvXIJFnwkd",
        "outputId": "2266c471-3553-4d83-f6ea-4b60c599d1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tweet.csv', 'Company_Tweet.csv', 'Company.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read csv for tweetcsv\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('omermetinn_tweets_about_the_top_companies_from_2015_to_2020_path/Tweet.csv')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "CzyzPa53n3v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">Sentiment Analysis for \"AAPL\" using twitter data - Yearly data</h2>\n",
        "<p>This notebook will examine the relationship between twitter sentiment and stock price.</p>\n",
        "<h2 style=\"color: darkblue;\">Part 1 of the notebook focusses on sentiment analysis</h2>\n",
        "<p>I have used NLTK's built-in, pretrained sentiment analyzer VADER (Valence Aware Dictionary and sEntiment Reasoner).\n",
        "The pre-trained sentiment analyzer returns the 'compound' score for each tweet. This score ranges from -1 (most negative) to +1 ( most positive).</p>\n",
        "<h2 style=\"color: darkblue;\">Part 2 of the notebook establishes the relationship between twitter sentiment & stock price</h2>\n",
        "<p>I have downloaded the stock data for Apple from yfinance.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "y7pYEBOPlTfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as tkr\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:11.039248Z",
          "iopub.execute_input": "2023-10-25T17:12:11.039626Z",
          "iopub.status.idle": "2023-10-25T17:12:11.111154Z",
          "shell.execute_reply.started": "2023-10-25T17:12:11.039593Z",
          "shell.execute_reply": "2023-10-25T17:12:11.109655Z"
        },
        "trusted": true,
        "id": "OrGtOSaplTfl",
        "outputId": "1f6ac8a2-715f-4386-9b98-c83a0996d778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tweets\n",
        "tweets=pd.read_csv('/root/.cache/kagglehub/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020/Tweet.csv')\n",
        "company_tweet=pd.read_csv('/kaggle/input/tweets-about-the-top-companies-from-2015-to-2020/Company_Tweet.csv')\n",
        "\n",
        "tweets=tweets.merge(company_tweet,how='left',on='tweet_id')\n",
        "# format dates\n",
        "tweets['date'] = pd.to_datetime(tweets['post_date'], unit='s').dt.date\n",
        "tweets.date=pd.to_datetime( tweets.date,errors='coerce')\n",
        "tweets['time'] = pd.to_datetime(tweets['post_date'], unit='s').dt.time"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:11.113129Z",
          "iopub.execute_input": "2023-10-25T17:12:11.113448Z",
          "iopub.status.idle": "2023-10-25T17:12:28.333544Z",
          "shell.execute_reply.started": "2023-10-25T17:12:11.113422Z",
          "shell.execute_reply": "2023-10-25T17:12:28.331857Z"
        },
        "trusted": true,
        "id": "agtVnRj_lTfl",
        "outputId": "017c39cb-f817-4ae6-ab8f-e1871d5c49a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020/Tweet.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-64c339eca256>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.cache/kagglehub/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020/Tweet.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcompany_tweet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/tweets-about-the-top-companies-from-2015-to-2020/Company_Tweet.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_tweet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/omermetinn/tweets-about-the-top-companies-from-2015-to-2020/Tweet.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gPlk-QhnlqnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">Table/Dataframe for all tweets related to apple in 2018</h2>\n",
        "<p>View the tweet data for apple below. The data shows twitter handle/name along with the body. The body text is used to estimate the sentiment score.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "e4DxPEwWlTfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:28.335838Z",
          "iopub.execute_input": "2023-10-25T17:12:28.336298Z",
          "iopub.status.idle": "2023-10-25T17:12:28.351056Z",
          "shell.execute_reply.started": "2023-10-25T17:12:28.336262Z",
          "shell.execute_reply": "2023-10-25T17:12:28.349721Z"
        },
        "trusted": true,
        "id": "FDqDOVUrlTfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment(tweets,ticker='AAPL',start='2018-01-01',end='2018-12-31'):\n",
        "    #sbuset\n",
        "    df=tweets.loc[((tweets.ticker_symbol==ticker)&(tweets.date>=start)&(tweets.date<=end))]\n",
        "    # applt the SentimentIntensityAnalyzer\n",
        "    df.loc[:,('score')]=df.loc[:,'body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "    # create label\n",
        "    #bins= pd.interval_range(start=-1, freq=3, end=1)\n",
        "    df.loc[:,('label')]=pd.cut(np.array(df.loc[:,'score']),bins=[-1, -0.66, 0.32, 1],right=True ,labels=[\"bad\", \"neutral\", \"good\"])\n",
        "\n",
        "    df=df.loc[:,[\"date\",\"score\",\"label\",\"tweet_id\",\"body\"]]\n",
        "    return df\n",
        "\n",
        "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
        "sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now ')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:28.352946Z",
          "iopub.execute_input": "2023-10-25T17:12:28.353994Z",
          "iopub.status.idle": "2023-10-25T17:12:28.377818Z",
          "shell.execute_reply.started": "2023-10-25T17:12:28.353934Z",
          "shell.execute_reply": "2023-10-25T17:12:28.376511Z"
        },
        "trusted": true,
        "id": "hyQxmyY7lTfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">On augmenting the library with stock market jargons / lingo, the sentiment score changes & is a better representation of the actual sentiment</h2>\n",
        "<p>For the same comments/tweets as in the previous cell, the score becomes more negative (skewed towards negative) after augmenting the library. Notice the results from the below cell.</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "EdMcPu-nlTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# augment vocab\n",
        "\n",
        "positive_words='high profit Growth Potential Opportunity Bullish Strong Valuable Success Promising Profitable Win Winner Outstanding Record Earnings Breakthrough buy bull long support undervalued underpriced cheap upward rising trend moon rocket hold breakout call beat support buying holding'\n",
        "negative_words='resistance squeeze cover seller Risk Loss Decline Bearish Weak Declining Uncertain Troubling Downturn Struggle Unstable Volatile Slump Disaster Plunge sell bear bubble bearish short overvalued overbought overpriced expensive downward falling sold sell low put miss'\n",
        "\n",
        "dictOfpos = { i : 4 for i in positive_words.split(\" \") }\n",
        "dictOfneg = { i : -4 for i in negative_words.split(\" \")  }\n",
        "Financial_Lexicon = {**dictOfpos, **dictOfneg}\n",
        "\n",
        "sia.lexicon.update(Financial_Lexicon)\n",
        "\n",
        "\n",
        "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
        "sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now ')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:28.380536Z",
          "iopub.execute_input": "2023-10-25T17:12:28.380926Z",
          "iopub.status.idle": "2023-10-25T17:12:28.397879Z",
          "shell.execute_reply.started": "2023-10-25T17:12:28.38088Z",
          "shell.execute_reply": "2023-10-25T17:12:28.396373Z"
        },
        "trusted": true,
        "id": "NVNtfLEqlTfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">NOTE</h2>\n",
        "<p>Below table highlights the sentiment score and the label as estimated using the nltk pre-trained library VADER..</p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "cuY-Tof-lTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start='2018-01-01'\n",
        "end='2018-12-31'\n",
        "ticker='AAPL'\n",
        "tw=get_sentiment(tweets,ticker,start,end) # get tweets\n",
        "tw.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:12:28.399579Z",
          "iopub.execute_input": "2023-10-25T17:12:28.399882Z",
          "iopub.status.idle": "2023-10-25T17:13:27.89537Z",
          "shell.execute_reply.started": "2023-10-25T17:12:28.399851Z",
          "shell.execute_reply": "2023-10-25T17:13:27.894005Z"
        },
        "trusted": true,
        "id": "xr2CDc4ClTfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">Exhibit</h2>\n",
        "<p>Distribution of positive, negative & neutral sentiment by each day.</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Kp8fEbsSlTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# Convert the 'date' column to datetime objects\n",
        "tw['date'] = pd.to_datetime(tw['date'])\n",
        "\n",
        "# Group the data by date and 'label' and count the number of tweets\n",
        "sentiment_counts = tw.groupby(['date', 'label']).size().unstack(fill_value=0)\n",
        "\n",
        "# Create an area chart\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Set colors for 'good,' 'neutral,' and 'bad'\n",
        "colors = {'good': 'green', 'neutral': 'grey', 'bad': 'red'}\n",
        "\n",
        "area = sentiment_counts.plot.area(stacked=True, ax=ax, color=[colors[c] for c in sentiment_counts.columns])\n",
        "\n",
        "# Customize the legend\n",
        "handles = [mpatches.Patch(color=colors[label], label=label.capitalize()) for label in sentiment_counts.columns]\n",
        "ax.legend(handles=handles, title='Sentiment', loc=\"upper left\")\n",
        "\n",
        "# Customize the chart\n",
        "plt.title('Sentiment Distribution by Date (2018)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Tweets')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:27.898061Z",
          "iopub.execute_input": "2023-10-25T17:13:27.898569Z",
          "iopub.status.idle": "2023-10-25T17:13:28.372838Z",
          "shell.execute_reply.started": "2023-10-25T17:13:27.89853Z",
          "shell.execute_reply": "2023-10-25T17:13:28.371777Z"
        },
        "trusted": true,
        "id": "L4505Cv0lTfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">NOTE</h2>\n",
        "<p>The sentiment score is created for each tweet and hence there are multiple sentiment scores for each day. The below code averages out the sentiment score for each day. The average score is then plotted as a line graph. It is noted that the average sentiment score is always positive due to the fact that the overall sentiment score for each day throughout the year is positive (or in other words, there are more positive or neutral tweets that negative tweets). This can also be observed in the above chart which highlights the frequency of positive, negative & neutral tweets.</p>\n",
        "</div>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8FSdpOxslTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'date' column to datetime objects\n",
        "tw['date'] = pd.to_datetime(tw['date'])\n",
        "\n",
        "# Group the data by date and calculate the average sentiment score for each day\n",
        "daily_sentiment = tw.groupby(tw['date'].dt.date)['score'].mean()\n",
        "\n",
        "daily_sentiment_df = pd.DataFrame({'Date': daily_sentiment.index, 'Average Score': daily_sentiment.values})\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "daily_sentiment_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:28.374213Z",
          "iopub.execute_input": "2023-10-25T17:13:28.375442Z",
          "iopub.status.idle": "2023-10-25T17:13:28.463393Z",
          "shell.execute_reply.started": "2023-10-25T17:13:28.375388Z",
          "shell.execute_reply": "2023-10-25T17:13:28.462502Z"
        },
        "trusted": true,
        "id": "3ie8JXQglTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">Exhibit</h2>\n",
        "<p>Average sentiment score for tweets related to Apple for each day of the year 2018.</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "3jK1kaLClTfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot the average sentiment scores\n",
        "ax.plot(daily_sentiment.index, daily_sentiment, marker='o', linestyle='-', color='b')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Average Sentiment Score')\n",
        "plt.title('Average Sentiment Score for Each Day for the year 2018')\n",
        "\n",
        "# Format x-axis date labels\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:28.464568Z",
          "iopub.execute_input": "2023-10-25T17:13:28.464837Z",
          "iopub.status.idle": "2023-10-25T17:13:28.823642Z",
          "shell.execute_reply.started": "2023-10-25T17:13:28.464814Z",
          "shell.execute_reply": "2023-10-25T17:13:28.822514Z"
        },
        "trusted": true,
        "id": "kXl45ExzlTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:28.825068Z",
          "iopub.execute_input": "2023-10-25T17:13:28.825428Z",
          "iopub.status.idle": "2023-10-25T17:13:38.854001Z",
          "shell.execute_reply.started": "2023-10-25T17:13:28.825366Z",
          "shell.execute_reply": "2023-10-25T17:13:38.852167Z"
        },
        "trusted": true,
        "id": "1wLUbnHylTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">The apple stock data is obtained from yfinance.</h2>\n",
        "<p>1. The first plot highlights the stock price since beginning.\n",
        "2. The second plot higlights the stock price change over 2018 (full year).</p>\n",
        "</div>"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T16:54:31.936167Z",
          "iopub.execute_input": "2023-10-25T16:54:31.93653Z",
          "iopub.status.idle": "2023-10-25T16:54:31.944693Z",
          "shell.execute_reply.started": "2023-10-25T16:54:31.936503Z",
          "shell.execute_reply": "2023-10-25T16:54:31.943303Z"
        },
        "id": "058gq-vNlTfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "aapl = yf.Ticker(\"AAPL\")\n",
        "hist = aapl.history(period=\"max\")\n",
        "hist[\"Open\"].plot(figsize=(15, 5), title=\"AAPL Stock Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:38.858311Z",
          "iopub.execute_input": "2023-10-25T17:13:38.858678Z",
          "iopub.status.idle": "2023-10-25T17:13:39.693221Z",
          "shell.execute_reply.started": "2023-10-25T17:13:38.858646Z",
          "shell.execute_reply": "2023-10-25T17:13:39.691718Z"
        },
        "trusted": true,
        "id": "5E5A-nHUlTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the stock symbol and date range\n",
        "stock_symbol = \"AAPL\"\n",
        "start_date = \"2018-01-01\"\n",
        "end_date = \"2018-12-31\"\n",
        "\n",
        "# Create a Ticker object for the stock\n",
        "stock = yf.Ticker(stock_symbol)\n",
        "\n",
        "# Fetch historical data for the specified date range\n",
        "hist = stock.history(period=\"1d\", start=start_date, end=end_date)\n",
        "\n",
        "# Plot the opening prices for the specified date range\n",
        "hist[\"Close\"].plot(figsize=(15, 5), title=f\"{stock_symbol} Stock Price (Jan 1, 2018 - Dec 31, 2018)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:39.695224Z",
          "iopub.execute_input": "2023-10-25T17:13:39.695592Z",
          "iopub.status.idle": "2023-10-25T17:13:40.12461Z",
          "shell.execute_reply.started": "2023-10-25T17:13:39.695561Z",
          "shell.execute_reply": "2023-10-25T17:13:40.123513Z"
        },
        "trusted": true,
        "id": "scbhZYV5lTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the start and end dates\n",
        "start_date = '2018-01-01'\n",
        "end_date = '2018-12-31'\n",
        "\n",
        "# Create a date range covering the full date range (including weekends and holidays)\n",
        "date_range = pd.date_range(start=start_date, end=end_date)\n",
        "\n",
        "# Create a new DataFrame with the full date range\n",
        "full_hist = pd.DataFrame(index=date_range)\n",
        "\n",
        "# Ensure that the timezone information for both DataFrames matches\n",
        "full_hist.index = full_hist.index.tz_localize(hist.index.tz)\n",
        "\n",
        "# Merge or combine the new DataFrame with the existing 'hist' DataFrame\n",
        "full_hist = full_hist.combine_first(hist)\n",
        "\n",
        "# Now, 'full_hist' contains all dates within the specified date range\n",
        "# with weekends and holidays included, and missing values are filled with NaN.\n",
        "\n",
        "# If you want to fill NaN values with 0, you can do:\n",
        "full_hist = full_hist.fillna(0)\n",
        "\n",
        "# Print or use the updated DataFrame 'full_hist'\n",
        "full_hist.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:40.125731Z",
          "iopub.execute_input": "2023-10-25T17:13:40.127085Z",
          "iopub.status.idle": "2023-10-25T17:13:40.149999Z",
          "shell.execute_reply.started": "2023-10-25T17:13:40.127037Z",
          "shell.execute_reply": "2023-10-25T17:13:40.148375Z"
        },
        "trusted": true,
        "id": "9wiG0-zqlTfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: lightblue; padding: 10px; border: 1px solid blue;\">\n",
        "<h2 style=\"color: darkblue;\">Exhibit</h2>\n",
        "<p>Plotting the sentiment and the stock price in one chart so as to spot any trend/patterns between the two, through manual eye-balling\n",
        ".</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "mkSlJSo_lTfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract data from dataframes\n",
        "dates = full_hist.index\n",
        "stock_prices = full_hist['Close']\n",
        "sentiment_scores = daily_sentiment_df['Average Score']\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot stock prices as a bar chart on the first axis (left y-axis)\n",
        "ax1.bar(dates, stock_prices, color='lightblue', label='Stock Price')\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Stock Price', color='b')\n",
        "\n",
        "# Create a second axis (right y-axis) for sentiment scores\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(dates, sentiment_scores, color='darkred', label='Sentiment Score')\n",
        "ax2.set_ylabel('Sentiment Score', color='r')\n",
        "\n",
        "# Add a legend\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
        "\n",
        "# Set a title\n",
        "plt.title('Apple Stock Price (Bar Chart) and Average Twitter Sentiment Score (Line Chart)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T17:13:40.151585Z",
          "iopub.execute_input": "2023-10-25T17:13:40.151994Z",
          "iopub.status.idle": "2023-10-25T17:13:41.144312Z",
          "shell.execute_reply.started": "2023-10-25T17:13:40.151965Z",
          "shell.execute_reply": "2023-10-25T17:13:41.143118Z"
        },
        "trusted": true,
        "id": "te5ltbnvlTfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}